{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7NFI-QPeO0k8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torchvision.transforms` 是 pytorch 中的图像预处理包。一般用Compose把多个步骤整合到一起\n",
        "\n",
        "Normalize：Normalized an tensor image with mean and standard deviation\n",
        "\n",
        "ToTensor：convert a PIL image to tensor $(H*W*C)$ in range $[0,255]$ to a torch.Tensor $(C*H*W)$ in the range $[0.0,1.0]$\n"
      ],
      "metadata": {
        "id": "9vstZBVxYLTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "transform = transforms.Compose([transforms.ToTensor(), # 将图片格式转换为 tensor\n",
        "                transforms.Normalize((0.1307,), (0.3081,))]) # 归一化\n",
        "\n",
        "train_dataset = datasets.MNIST(root='../dataset/mnist/',\n",
        "                  train=True,\n",
        "                  transform=transform,\n",
        "                  download=True)\n",
        "test_dataset = datasets.MNIST(root='../dataset/mnist/',\n",
        "                  train=False,\n",
        "                  transform=transform,\n",
        "                  download=True)\n",
        "train_loader = DataLoader(dataset=train_dataset, \n",
        "              batch_size=batch_size,\n",
        "              shuffle=True,\n",
        "              )\n",
        "test_loader = DataLoader(dataset=test_dataset,\n",
        "              batch_size=batch_size,\n",
        "              shuffle=False,\n",
        "              )"
      ],
      "metadata": {
        "id": "puoQ6CTXPJjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.linear1 = torch.nn.Linear(784, 512)\n",
        "    self.linear2 = torch.nn.Linear(512, 256)\n",
        "    self.linear3 = torch.nn.Linear(256, 128)\n",
        "    self.linear4 = torch.nn.Linear(128, 64)\n",
        "    self.linear5 = torch.nn.Linear(64, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 784) # 输入的维度是(N,1,28,28)，但是在全连接网络里，需要变为一阶的向量（N，784），使用x=x.view(-1,784),这里的-1是指根据784自动算出的维度\n",
        "    x = F.relu(self.linear1(x))\n",
        "    x = F.relu(self.linear2(x))\n",
        "    x = F.relu(self.linear3(x))\n",
        "    x = F.relu(self.linear4(x))\n",
        "\n",
        "    return self.linear5(x) # 最后一层不做激活，在使用交叉熵CELoss作为损失函数时，会自动调用softmax函数将最后一层激活\n",
        "\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "UNrG16_uQ3A_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5) # momentum动量，可以理解为给物体一个惯性，容易越过局部极小点，一般设置为0.5"
      ],
      "metadata": {
        "id": "W8GfIy2YRx0k"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "  loss_sum = 0\n",
        "  for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "    y_pred = model(inputs)\n",
        "    loss = criterion(y_pred, labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    loss_sum += loss.item()\n",
        "    if i % 300 == 299: # 每300个batch输出损失\n",
        "      print(\"[%d, %5d] loss:%.3f\" % (epoch+1, i+1, loss_sum/300))\n",
        "      loss = 0"
      ],
      "metadata": {
        "id": "QrvD5ZNVSAxs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.max()` 第一个参数返回指定行的最大值，第二个参数返回指定行最大值的下标"
      ],
      "metadata": {
        "id": "yRKSefd4a3D2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test():\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  # 测试集不计算梯度\n",
        "  with torch.no_grad():\n",
        "    for (inputs, labels) in test_loader:\n",
        "      y_pred = model(inputs)\n",
        "      _, predicted = torch.max(y_pred.data, dim=1) # dim = 1 列是第0个维度，行是第1个维度\n",
        "      total += batch_size \n",
        "      correct += (predicted == labels).sum().item() # \n",
        "  print('accuracy on test set: %d %% ' % (100*correct/total))"
      ],
      "metadata": {
        "id": "BMdxwJKbVFS0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "  for epoch in range(10):\n",
        "    train(epoch)\n",
        "    test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_evnZrG6VwHF",
        "outputId": "6f508246-7198-4db2-f73e-53f207a05abd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1,   300] loss:2.259\n",
            "[1,   600] loss:3.348\n",
            "[1,   900] loss:3.772\n",
            "accuracy on test set: 88 % \n",
            "[2,   300] loss:0.312\n",
            "[2,   600] loss:0.592\n",
            "[2,   900] loss:0.830\n",
            "accuracy on test set: 93 % \n",
            "[3,   300] loss:0.194\n",
            "[3,   600] loss:0.364\n",
            "[3,   900] loss:0.521\n",
            "accuracy on test set: 95 % \n",
            "[4,   300] loss:0.136\n",
            "[4,   600] loss:0.258\n",
            "[4,   900] loss:0.375\n",
            "accuracy on test set: 95 % \n",
            "[5,   300] loss:0.101\n",
            "[5,   600] loss:0.192\n",
            "[5,   900] loss:0.285\n",
            "accuracy on test set: 96 % \n",
            "[6,   300] loss:0.074\n",
            "[6,   600] loss:0.152\n",
            "[6,   900] loss:0.229\n",
            "accuracy on test set: 96 % \n",
            "[7,   300] loss:0.060\n",
            "[7,   600] loss:0.120\n",
            "[7,   900] loss:0.185\n",
            "accuracy on test set: 96 % \n",
            "[8,   300] loss:0.045\n",
            "[8,   600] loss:0.097\n",
            "[8,   900] loss:0.150\n",
            "accuracy on test set: 97 % \n",
            "[9,   300] loss:0.041\n",
            "[9,   600] loss:0.084\n",
            "[9,   900] loss:0.126\n",
            "accuracy on test set: 97 % \n",
            "[10,   300] loss:0.031\n",
            "[10,   600] loss:0.065\n",
            "[10,   900] loss:0.097\n",
            "accuracy on test set: 97 % \n"
          ]
        }
      ]
    }
  ]
}